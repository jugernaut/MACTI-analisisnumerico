{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CudaNumbaParalelo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jugernaut/MACTI-analisisnumerico/blob/josue/09_ProgramacionParalelo/CPU/02_CudaNumbaParalelo_SCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfK9rERkrYO0"
      },
      "source": [
        "<font color=\"Teal\" face=\"Comic Sans MS,arial\">\n",
        "  <h1 align=\"center\"><i>Programación en Paralelo</i></h1>\n",
        "  </font>\n",
        "  <font color=\"Black\" face=\"Comic Sans MS,arial\">\n",
        "  <h5 align=\"center\"><i>Profesor: M. en C. Miguel Angel Pérez León</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Jesús Iván Coss Calderón</i></h5>\n",
        "    <h5 align=\"center\"><i>Ayudante: Mario Arturo Nieto Butron</i></h5>\n",
        "  <h5 align=\"center\"><i>Materia: Seminario de programación en paralelo</i></h5>\n",
        "  </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXfJOpOItu22"
      },
      "source": [
        "# Introducción\n",
        "\n",
        "Todos los algoritmos vistos en el curso se han descrito de manera [secuencial](https://desarrolloweb.com/articulos/2199.php); sin embargo,muchos de ellos pueden ser redefinidos en su forma en **paralelo**.\n",
        "\n",
        "¿Por qué nos debería interesar programar en paralelo?, bueno la respuesta es muy sencilla, la gran mayoría (si no es que todas) de las aplicaciones que usamos actualmente son desarrolladas usando alguna técnica de programación en paralelo.\n",
        "\n",
        "¿Cuál es la principal ventaja de la programación en paralelo?, **la velocidad con la que este se ejecuta**, es decir el tiempo de ejecución. Un algoritmo en paralelo, debido a que distribuye los cálculos (*FLOP's*) entre los distintos dispositivos de cómputo tiende a reducir el tiempo de ejecución.\n",
        "\n",
        "*CUDA* (estándar de programación en paralelo basado en el lenguaje *C/C++*) tiene un modelo de ejecución diferente al modelo secuencial tradicional utilizado para programar usando los *CPU's* disponibles. En *CUDA*, el código que escribes será ejecutado por varios subprocesos a la vez (a menudo cientos o miles dentro de la *GPU*), a diferencia de la programación secuencial en la cual cada [proceso](http://tecnologiasifa4b.blogspot.com/2015/08/proceso-computacional.html#:~:text=Un%20proceso%20computacional%20es%20u,de%20recursos%20del%20sistema%20asociados.&text=La%20ejecuci%C3%B3n%2C%20desde%20un%20proceso,la%20creaci%C3%B3n%20de%20otro%20proceso.) es ejecutado uno a la vez por cada *CPU*. Su solución se modelará definiendo una jerarquía de subprocesos de cuadrícula, bloques y subprocesos.\n",
        "\n",
        "Una de las bibliotecas que da soporte a *CUDA* para *Python* recibe el nombre de *Numba* ([envoltorio](https://es.wikipedia.org/wiki/Wrapper) de *CUDA* para python). Mediante Numba podemos acceder a las instalaciones para declarar y administrar las características que ofrece *CUDA*. Las instalaciones y prestaciones son muy similares a las expuestas por el lenguaje *C/C++* para *CUDA* de *Nvidia*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lxaDk7Y_8D-"
      },
      "source": [
        "## *CPU* v.s. *GPU*\n",
        "\n",
        "Actualmente los dispositivos de cómputo contienen al menos un *CPU* y dentro de este *CPU* pueden estar contenidos varios núcleos, lo que permite el desarrollo de algoritmos en paralelo.\n",
        "\n",
        "De igual manera, la mayoría de los dispositivos de cómputo contienen al menos un *GPU* y dentro de este *GPU* pueden existir varios núcleos, la principal diferencia entre ambos (*CPU* y *GPU*) es el propósito para el cuál fueron diseñados\n",
        "\n",
        "Para fines prácticos (y del curso) podemos pensar que la diferencia principal entre una *CPU* (unidad de procesamiento central) y una *GPU* (**unidad de procesamiento gráfico**) radica en que un *CPU* es un dispositivo de cómputo de propósito general, puede realizar cualquier tipo de cómputo que se le asigne.\n",
        "\n",
        "Por otro lado un *GPU* esta diseñada para el procesamiento gráfico, lo que significa que la forma en la que procesa información **esta optimizada para trabajar con matrices y vectores**.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/desarrollo/Figuras/MonteCarlo/cpu-vs-gpu.jpg?raw=1\" width=\"600\">\n",
        "</center>\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/desarrollo/Figuras/MonteCarlo/mejor.png?raw=1\" width=\"600\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atxBpfns3ZNQ"
      },
      "source": [
        "## Ley de Moore\n",
        "\n",
        "El número de transistores por unidad de superficie en circuitos integrados, se duplicara cada año. En consecuencia, la velocidad de cómputo relacionada directamente al hardware se vera duplicada cada año.\n",
        "\n",
        "<center>\n",
        "<img src=\"https://github.com/jugernaut/Numerico2021/blob/desarrollo/Figuras/MonteCarlo/more2.jpg?raw=1\" width=\"800\">\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GALRqhRpue9q"
      },
      "source": [
        "## ¿Qué es *Numba*?\n",
        "\n",
        "Según la documentación de *Numba*, \"*Numba* es un compilador justo a tiempo para *Python* que funciona mejor en código que usa matrices, funciones de *Numpy* y ciclos.\n",
        "\n",
        "En otras palabras, *Numba* es una paquetería (igual que *Numpy* o *Matplotlib*) que nos ayuda a que nuestros algoritmos se ejecuten de forma optimizada y en particular nos permite tener acceso a los *GPU's* disponibles en el hardware que estemos ejecutando nuestros algoritmos.\n",
        "\n",
        "La forma más común de usar *Numba* es a través de su colección de *decoradores* que se pueden aplicar a sus funciones para indicarle a *Numba* que las compile. Cuando se realiza una llamada a una función decorada de *Numba*, **se compila en código máquina** \"justo a tiempo\" para su ejecución y todo o parte de su código puede ejecutarse posteriormente a la ¡velocidad del código máquina nativo!.\n",
        "\n",
        "Para nuestros propósitos de hoy, *Numba* es un paquete de *Python* que le permite escribir código *Python* para *GPU*, y también puede usarse para programación en paralelo mediante *CPU's*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-2DoUsM7sNr"
      },
      "source": [
        "## Dependencia Funcional\n",
        "\n",
        "Existen muchas formas para poder identificar si existe la posibilidad de emplear alguna técnica de paralelización algun algoritmo.\n",
        "\n",
        "Sin embargo la forma más sencilla de saber cuando NO ES POSIBLE programar algún algoritmo en su equivalente en paralelo, es mediante las dependencias funcionales.\n",
        "\n",
        "La idea de **dependencia funcional** es la generalización del concepto de **dependencia lineal**. Se dice que un conjunto de funciones es **funcionalmente dependiente** si existe una relación funcional entre ellas, en otras palabras cuando alguna de las funciones del conjunto es expresable como función de las otras funciones definidas previamente dentro del conjunto.\n",
        "\n",
        "Esto significa que cuando existe una dependencia funcional, para poder obtener el resultado del algoritmo $f_n(f_{n-1}(x))$ es necesario esperar el resultado de $f_{n-1}(x)$, lo que implica que este tipo de algoritmos no es candidato a ser programado en paralelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bL76D-t2fql"
      },
      "source": [
        "## Ley de Amdahl\n",
        "\n",
        "Sea $f$ la fracción de operaciones en un calculo computacional que será llevado a cabo de manera secuencial, donde $0\\leq f\\leq1$.\n",
        "\n",
        "La máxima velocidad $\\Psi$ alcanzada mediante programación en paralelo con una computadora con $p$ unidades de procesamiento enfocadas en el mismo calculo es:\n",
        "\n",
        "$$\\Psi\\leq\\frac{1}{f+(1-f)/p}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7J7oOHfwBeM"
      },
      "source": [
        "# Sintaxis *Numba*\n",
        "\n",
        "Al hacer uso de *Numba* (*CUDA*), debemos tomar en cuenta que la finalidad de *Numba* es acelerar el desempeño de nuestros algoritmos.\n",
        "\n",
        "Para llevar a cabo tal propósito, *Numba* provee de sentencias que se agregan al código de *Python* conocidos como *decoradores*. Estos decoradores son de diferentes tipos, ya que *Numba* permite acelerar el desempeño de diferentes formas.\n",
        "\n",
        "Mediante *Numba* los cálculos de nuestros algoritmos se pueden distribuir entre el *CPU* y el *GPU*, es por eso que *Numba* nos ofrece una forma para distinguir cuáles de nuestras funciones se ejecutan en uno u otro dispositivo de cómputo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlujxYcPPsor"
      },
      "source": [
        "### `nopython=True`\n",
        "\n",
        "El decorador más sencillo de usar en *Numba* es el decorador `@jit` (*Just in time*) y permite recibir múltiples parámetros que indican la forma en la que se quiere optimizar el código (ver referencias). Si se usa este decorador sin parámetros *Numba* decide cuál es la mejor forma para optimizar el desempeño del algoritmo.\n",
        "\n",
        "Uno de sus parámetros más elementales pero al mismo tiempo uno de los más usados, es el parametro `nopython=True`.\n",
        "\n",
        "Al hacer uso de este decorador se le indica a *Numba* que el código que pertenece a esta definición debe ser optimizado y esto se lleva a cabo, convirtiendo el código de python en **código de máquina**, esto toma un poco más de tiempo la primera vez que se ejecuta, pero las siguientes veces tomará mucho menos tiempo que una función en *Python* nativo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8tNuU3pjVAK"
      },
      "source": [
        "import random\n",
        "# biblioteca de Numba\n",
        "from numba import jit\n",
        "\n",
        "#¡¡¡descomentar para optimizar, te vas a sorprender!!!\n",
        "@jit(nopython=True)\n",
        "def mc_pi_aprox(n=100000000):\n",
        "    dentro_circulo = 0\n",
        "    for i in range(n):\n",
        "      x = random.random()\n",
        "      y = random.random()\n",
        "      # valores dentro de la circunferencia\n",
        "      if (x**2+y**2 < 1):\n",
        "          dentro_circulo += 1\n",
        "    return 4*dentro_circulo / n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mLldJZM95rm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53d694b-26ad-4abe-e2a0-998d53fe2418"
      },
      "source": [
        "%%time\n",
        "mc_pi_aprox()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.42 s, sys: 6.28 ms, total: 1.42 s\n",
            "Wall time: 1.42 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.14175072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8LzorbuqUr2"
      },
      "source": [
        "En el ejemplo de la celda superior en la cual se aproxima el valor de $\\pi$ mediante Monte Carlo, al ejecutarlo sin el uso de *Numba* (solo *Python* nativo), podemos notar que el tiempo de ejecución se incrementa de manera proporcional a la precisión que usemos.\n",
        "\n",
        "Por otro lado, si se usa el decorador *@jit(nopython=True)*, qué es equivalente a *@njit*, de manera explícita se le pide a *Numba*, que convierta el **código a código de máquina**. Y el tiempo de ejecución disminuye de manera notable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiMtF_AR1Vg2"
      },
      "source": [
        "### `parallel` (*OpenMP*)\n",
        "\n",
        "Otro parámetro muy útil pero a la vez 'obscuro' es, `@njit(parrallel=True)`.\n",
        "\n",
        "Este decorador va de la mano de la palabra reservada `prange` y en conjunto permiten ejecutar en paralelo ciclos dentro de la función definida.\n",
        "\n",
        "Este decorador oculta mucho del proceso que se realiza al ejecutar un algoritmo en paralelo. Sin embargo ya que a esta altura del curso se conoce cual es el trasfondo (*OpenMP, MPI, CUDA*), podemos obviar el mismo.\n",
        "\n",
        "La parlabra reservada `prange` se emplea para especificar el ciclo que se quiere realizar en paralelo y no solo eso, también realiza la operación conocida como *reduction* de alguna variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os9I6k8F-qLI"
      },
      "source": [
        "# import de biblioteca calculos numericos\n",
        "import math\n",
        "\n",
        "# aproximacion de Pi mediante sumas de Reimann (version secuencial)\n",
        "def aproxPIsec(n=10000000):\n",
        "    suma=0\n",
        "    # funcion a integrar\n",
        "    f = lambda x: math.sqrt(1-x**2)\n",
        "    delta = 1/n\n",
        "    for i in range(1,n+1):\n",
        "        #x = delta*(i-0.5) #punto medio\n",
        "        x = delta*(i)\n",
        "        suma += f(x)\n",
        "    aproximacion = delta*suma*4\n",
        "    return aproximacion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6II7oIQY-07G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "910950ec-1be6-436d-81f8-7924e7e2ba50"
      },
      "source": [
        "%%time\n",
        "aproxPIsec()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.61 s, sys: 10.9 ms, total: 3.62 s\n",
            "Wall time: 3.63 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.1415924535527124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxroKejyBgsj"
      },
      "source": [
        "Usamos la 'función mágica' `%%time` para mostrar el tiempo y el resultado de la ejecución de la celda en la que se hace uso de la versión secuencial de este algoritmo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_bAbmcK_HZQ"
      },
      "source": [
        "# import de biblioteca calculos numericos y paralelizacion\n",
        "from numba import njit, prange, set_num_threads\n",
        "import numpy as np\n",
        "import math\n",
        "# fijamos desde código el numero de hilos\n",
        "set_num_threads(2)\n",
        "\n",
        "# aproximacion de Pi mediante sumas de Reimann (version paralela)\n",
        "@njit(parallel=True)\n",
        "def aproxPIpar(n=10000000):\n",
        "    suma=0\n",
        "    # funcion a integrar\n",
        "    f = lambda x: math.sqrt(1-x**2)\n",
        "    delta = 1/n\n",
        "    # prange indica que este for debe ser ejecutado en paralelo\n",
        "    for i in prange(1,n+1):\n",
        "        #x = delta*(i-0.5) #punto medio\n",
        "        x = delta*(i)\n",
        "        suma += f(x)\n",
        "    aproximacion = delta*suma*4\n",
        "    return aproximacion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YozECThR_mXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254fb651-4e54-4f52-e1be-e68ed41d21b2"
      },
      "source": [
        "%%time\n",
        "aproxPIpar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 446 ms, sys: 2.74 ms, total: 449 ms\n",
            "Wall time: 426 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.1415924535525024"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaUoB57BB0op"
      },
      "source": [
        "#### Versión en paralelo\n",
        "\n",
        "Hay varios puntos importantes a notar en la versión paralelo del algoritmo de la aproximación del valor de $\\pi$ mediante sumas de Raimann:\n",
        "\n",
        "1.   En la sección de imports, `njit`, `prange`, `set_num_threads`, estos son los elementos de *Numba* que nos permiten la ejecución de este algoritmo en paralelo.\n",
        "2.   El decorador `@njit(parallel=True)` en conjunto con `prange`, nos indican que secciones del código se ejecutará en paralelo.\n",
        "3.   *Numba* oculta la operación de *redcution sum*, de la variable `suma`.\n",
        "4.   El tiempo de ejecución disminuye bastante en la versión en paralelo con respecto a la versión secuencial y no así la precisión, de hecho podemos descomentar la linea inmediata debajo del ciclo `for` para mejorar la precisión del algoritmo al usar el punto medio.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga6ceh7EifNN"
      },
      "source": [
        "# Referencias\n",
        "\n",
        "1.   https://numba.pydata.org/numba-doc/latest/user/5minguide.html\n",
        "2.   http://numba.pydata.org/numba-doc/latest/user/threading-layer.html\n",
        "3.   https://numba.pydata.org/numba-doc/dev/user/jit.html\n",
        "4.   https://thedatafrog.com/en/articles/make-python-fast-numba/\n",
        "5.   https://people.duke.edu/~ccc14/sta-663/CUDAPython.html\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}